{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a45010e-dc0f-43d2-811d-1499e9c44844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch_rechub.models.multi_task import SharedBottom, ESMM, MMOE, PLE, AITM\n",
    "from torch_rechub.trainers import MTLTrainer\n",
    "from torch_rechub.basic.features import DenseFeature, SparseFeature\n",
    "from torch_rechub.utils.data import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af543b8f-f75f-419e-ab75-17f62274fc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2312562/2090339189.py:10: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  pd.np.random.seed(2023)\n"
     ]
    }
   ],
   "source": [
    "config_path = '/tmp/gaizhy/applied_algorithm/rampUp/applied_ag_utils'\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sys.path.append(config_path)  # append上三级目录，使之能加载dzj_toolkits包\n",
    "from gaizhy_utils import logger_initialize\n",
    "logger = logger_initialize('MMOE_rechub_train.log')\n",
    "\n",
    "random.seed(2023)\n",
    "np.random.seed(2023)\n",
    "pd.np.random.seed(2023)\n",
    "torch.manual_seed(2023)\n",
    "torch.cuda.manual_seed_all(2023)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee74c874-f828-4f86-b0ec-89c58ac7d4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# def datamaker(root_path,train_data_name,test_data_name,val_data_name,change_data_rate=0.05):\n",
    "#     origin_data_path = {'train':root_path+train_data_name,\n",
    "#                         'test':root_path+test_data_name,\n",
    "#                         'val':root_path+val_data_name\n",
    "#                        }\n",
    "#     for i in origin_data_path:\n",
    "#         data_path = origin_data_path[i]\n",
    "#         data = pd.read_csv(data_path) # 读取数据\n",
    "#         data.insert(1,'carts',0) # 插入标签数据\n",
    "        \n",
    "#         # 强制让购买行为下的加购行为标签为1\n",
    "#         data.loc[(data['click']==1)&(data['purchase']==1),'carts']=1\n",
    "\n",
    "#         # 找出可对加购标签进行修改的index\n",
    "#         change_index_list = list(data.loc[(data['click']==1)&(data['purchase']!=1),'carts'].index)\n",
    "\n",
    "#         # 按比例随机选取可进行修改的加购标签index\n",
    "#         change_number = round(len(change_index_list)*change_data_rate)\n",
    "#         selsct_change_index = random.sample(change_index_list,change_number)\n",
    "\n",
    "#         # 对随机选中的数据修改加购行为标签\n",
    "#         data.loc[selsct_change_index,'carts']=1\n",
    "        \n",
    "#         # 保存数据到原目录\n",
    "#         data.to_csv(data_path.split('.csv')[0]+'_add_data.csv',index = False)\n",
    "        \n",
    "#         print('%s数据集，可修改的点击标签有%d个，修改比例为%.2f，修改的加购行为标签数量为%d个'%(i,len(change_index_list),change_data_rate,change_number))\n",
    "        \n",
    "# root_path = '/tmp/gaizhy/aliccp/'\n",
    "# train_data_name = 'ali_ccp_train.csv'\n",
    "# test_data_name = 'ali_ccp_test.csv'\n",
    "# val_data_name = 'ali_ccp_val.csv'\n",
    "# change_data_rate = 0.05\n",
    "# datamaker(root_path,train_data_name,test_data_name,val_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2129fadc-ecb5-4ac5-838d-ebe98e345ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/tmp/gaizhy/aliccp'\n",
    "\n",
    "# df_train_origin = pd.read_csv(data_path + '/ali_ccp_train.csv', nrows=None)\n",
    "# df_val = pd.read_csv(data_path + '/ali_ccp_val.csv', nrows=None)\n",
    "# df_test = pd.read_csv(data_path + '/ali_ccp_test.csv', nrows=None)\n",
    "\n",
    "# df_train_origin = pd.read_csv(data_path + '/ali_ccp_train_with_carts.csv', nrows=None)\n",
    "# df_val = pd.read_csv(data_path + '/ali_ccp_val_with_carts.csv', nrows=None)\n",
    "# df_test = pd.read_csv(data_path + '/ali_ccp_test_with_carts.csv', nrows=None)\n",
    "\n",
    "df_train_origin = pd.read_csv(data_path + '/ali_ccp_train_with_carts.csv', nrows=None)\n",
    "df_val = pd.read_csv(data_path + '/ali_ccp_val_with_carts.csv', nrows=None)\n",
    "df_test = pd.read_csv(data_path + '/ali_ccp_test_with_carts.csv', nrows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bfc3261-38f6-46c8-ab8c-4b88bc1e2f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_origin.drop(columns=['Unnamed: 0', 'index', 'index.1', 'p_purchase', 'p_click'],inplace=True)\n",
    "df_val.drop(columns=['Unnamed: 0', 'index', 'index.1', 'p_purchase', 'p_click'], inplace=True)\n",
    "df_test.drop(columns=['Unnamed: 0', 'index', 'index.1', 'p_purchase', 'p_click'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab0d78d-4a18-4050-b8bc-d769bd742960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train_origin.loc[:,['click', 'purchase']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5039a-0dc6-477d-995b-514bdad3d168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_bal.loc[:,['click', 'purchase']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22f271c-6547-4e03-be08-0d2b09db1f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "click  carts  purchase\n",
       "0      0      0           40655649\n",
       "1      0      0            1517701\n",
       "       1      0             117753\n",
       "              1               8802\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_origin.loc[:,['click','carts','purchase']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd26bd38-9dae-4f98-a3b3-07a3ce001c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_pos = df_train_origin[df_train_origin['click']==1]\n",
    "print(train_data_pos.shape)\n",
    "train_data_neg = df_train_origin[df_train_origin['click']==0]\n",
    "train_data_neg = train_data_neg.sample(n=16442560)\n",
    "print(train_data_neg.shape)\n",
    "train_data_bal = pd.concat([train_data_pos,train_data_neg], axis=0)\n",
    "print(train_data_bal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694abd2c-d1fd-4e42-a888-587c8201ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_origin\n",
    "# df_train = train_data_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ce10231-424b-4755-9dfb-34192c2ea84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>click</th>\n",
       "      <th>purchase</th>\n",
       "      <th>101</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>128</th>\n",
       "      <th>...</th>\n",
       "      <th>150_14</th>\n",
       "      <th>D109_14</th>\n",
       "      <th>D110_14</th>\n",
       "      <th>D127_14</th>\n",
       "      <th>D150_14</th>\n",
       "      <th>D508</th>\n",
       "      <th>D509</th>\n",
       "      <th>D702</th>\n",
       "      <th>D853</th>\n",
       "      <th>carts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4734</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.07556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   click  purchase  101  121  122  124  125  126  127  128  ...  150_14  \\\n",
       "0      0         0    1    1    1    1    1    0    1    1  ...       1   \n",
       "\n",
       "   D109_14  D110_14  D127_14  D150_14     D508  D509  D702  D853  carts  \n",
       "0   0.4734    0.562   0.0856   0.1902  0.07556   0.0   0.0   0.0      0  \n",
       "\n",
       "[1 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "272356de-a17a-41cc-ae98-1322d8284532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : val : test = 42299905 21508307 21508307\n",
      "sparse cols:23 dense cols:8\n"
     ]
    }
   ],
   "source": [
    "print(\"train : val : test = %d %d %d\" % (len(df_train), len(df_val), len(df_test)))\n",
    "train_idx, val_idx = df_train.shape[0], df_train.shape[0] + df_val.shape[0]\n",
    "data = pd.concat([df_train, df_val, df_test], axis=0)\n",
    "#task 1 (as cvr): main task, purchase prediction\n",
    "#task 2(as ctr): auxiliary task, click prediction\n",
    "\n",
    "# data.rename(columns={'purchase': 'cvr_label', 'click': 'ctr_label'}, inplace=True)\n",
    "data.rename(columns={'purchase': 'cvr_label', 'carts': 'car_label','click': 'ctr_label'}, inplace=True)\n",
    "data[\"ctcvr_label\"] = data['cvr_label'] * data['ctr_label']\n",
    "\n",
    "col_names = data.columns.values.tolist()\n",
    "dense_cols = ['D109_14', 'D110_14', 'D127_14', 'D150_14', 'D508', 'D509', 'D702', 'D853']\n",
    "# sparse_cols = [col for col in col_names if col not in dense_cols and col not in ['cvr_label', 'ctr_label', 'ctcvr_label']]\n",
    "sparse_cols = [col for col in col_names if col not in dense_cols and col not in ['cvr_label', 'ctr_label', 'ctcvr_label', 'car_label']]\n",
    "print(\"sparse cols:%d dense cols:%d\" % (len(sparse_cols), len(dense_cols)))\n",
    "\n",
    "# label_cols = ['cvr_label', 'ctr_label']  #the order of labels can be any\n",
    "label_cols = ['cvr_label', 'car_label', 'ctr_label']  #the order of labels can be any\n",
    "used_cols = sparse_cols + dense_cols\n",
    "features = [SparseFeature(col, data[col].max()+1, embed_dim=4)for col in sparse_cols] \\\n",
    "           + [DenseFeature(col) for col in dense_cols]\n",
    "\n",
    "\n",
    "x_train, y_train = {name: data[name].values[:train_idx] for name in used_cols}, data[label_cols].values[:train_idx]\n",
    "x_val, y_val = {name: data[name].values[train_idx:val_idx] for name in used_cols}, data[label_cols].values[train_idx:val_idx]\n",
    "x_test, y_test = {name: data[name].values[val_idx:] for name in used_cols}, data[label_cols].values[val_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbb6ab5f-b546-412b-a921-d518be612d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch, learning_rate, batch_size, weight_decay, device, save_dir = 5, 1e-3, 8192, 1e-4, 'cuda:0', './'\n",
    "\n",
    "# elif model_name == \"MMOE\":\n",
    "# features, x_train, y_train, x_val, y_val, x_test, y_test = get_ali_ccp_data_dict(model_name)\n",
    "# task_types = [\"classification\", \"classification\"]\n",
    "task_types = [\"classification\", \"classification\", \"classification\"]\n",
    "\n",
    "dg = DataGenerator(x_train, y_train)\n",
    "train_dataloader, val_dataloader, test_dataloader = dg.generate_dataloader(x_val=x_val, y_val=y_val, x_test=x_test, y_test=y_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30317964-01b1-4935-9e96-d24c7f1200bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel running on these gpus: ['cuda:0', 'cuda:1']\n"
     ]
    }
   ],
   "source": [
    "# model = MMOE(features, task_types, 8, expert_params={\"dims\": [16]}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}])\n",
    "# model = MMOE(features, task_types, 8, expert_params={\"dims\": [16]}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}, {\"dims\": [8]}])\n",
    "# model = PLE(features, task_types, n_level=1, n_expert_specific=2, n_expert_shared=1, expert_params={\"dims\": [16], \"dropout\":0.05}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}])\n",
    "model = PLE(features, task_types, n_level=1, n_expert_specific=2, n_expert_shared=1, expert_params={\"dims\": [16], \"dropout\":0.05}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}, {\"dims\": [8]}])\n",
    "\n",
    "#adaptive weight loss:\n",
    "#mtl_trainer = MTLTrainer(model, task_types=task_types, optimizer_params={\"lr\": learning_rate, \"weight_decay\": weight_decay}, adaptive_params={\"method\": \"uwl\"}, n_epoch=epoch, earlystop_patience=10, device=device, model_path=save_dir)\n",
    "\n",
    "mtl_trainer = MTLTrainer(model, task_types=task_types, \n",
    "    optimizer_params={\"lr\": learning_rate, \"weight_decay\": weight_decay}, \n",
    "    n_epoch=epoch, earlystop_patience=10, device=device, gpus=['cuda:0', 'cuda:1'], model_path=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489bccd1-00e6-4098-93a2-4ccfd38ba069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  17%|█▋        | 883/5164 [01:14<06:01, 11.83it/s] "
     ]
    }
   ],
   "source": [
    "mtl_trainer.fit(train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a23677-7d68-4a75-8c03-510973277cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(mtl_trainer.model.state_dict(), 'MMOE_click&purchase.pt')\n",
    "# torch.save(mtl_trainer.model.state_dict(), 'MMOE_click&carts&purchase.pt')\n",
    "torch.save(mtl_trainer.model.state_dict(), 'PLE_click&carts&purchase.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d681df0a-ad41-4b0c-bd54-024bd053b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_trainer.model.load_state_dict(torch.load('MMOE_click&purchase.pt'))\n",
    "mtl_trainer.model.to(mtl_trainer.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6e06d1-f4e5-4627-9949-554c4a6647d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auc = mtl_trainer.evaluate(mtl_trainer.model, test_dataloader)\n",
    "logger.info(f'lr: {learning_rate}, bs: {batch_size}, wd: {weight_decay}')\n",
    "logger.info(f'test auc: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946d305-55b5-425e-b050-c115a74ac12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rates = [1e-3, 5e-4, 2.5e-4, 2e-3, 4e-3]\n",
    "batch_sizes = [1024, 512, 256, 2048, 4096]\n",
    "weight_decaies = [1e-4, 5e-5, 2.5e-5, 2e-4, 4e-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e6bf23-e2b0-46f1-9a91-54a4203a5484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser.add_argument('--epoch', type=int, default=1)\n",
    "# parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "# parser.add_argument('--batch_size', type=int, default=1024)\n",
    "# parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "# parser.add_argument('--device', default='cpu')  #cuda:0\n",
    "# parser.add_argument('--save_dir', default='./')\n",
    "# parser.add_argument('--seed', type=int, default=2022)\n",
    "for learning_rate in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for weight_decay in weight_decaies:\n",
    "            # epoch, learning_rate, batch_size, weight_decay, device, save_dir, seed = 10, 1e-3, 1024, 1e-4, 'cuda:0', './', 2022\n",
    "            epoch, device, save_dir, seed = 10, 'cuda:0', './', 2022\n",
    "\n",
    "            torch.manual_seed(seed)\n",
    "            # elif model_name == \"MMOE\":\n",
    "            # features, x_train, y_train, x_val, y_val, x_test, y_test = get_ali_ccp_data_dict(model_name)\n",
    "            task_types = [\"classification\", \"classification\"]\n",
    "            model = MMOE(features, task_types, 8, expert_params={\"dims\": [16]}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}])\n",
    "\n",
    "            dg = DataGenerator(x_train, y_train)\n",
    "            train_dataloader, val_dataloader, test_dataloader = dg.generate_dataloader(x_val=x_val, y_val=y_val, x_test=x_test, y_test=y_test, batch_size=batch_size)\n",
    "\n",
    "            #adaptive weight loss:\n",
    "            mtl_trainer = MTLTrainer(model, task_types=task_types, \n",
    "                optimizer_params={\"lr\": learning_rate, \"weight_decay\": weight_decay}, \n",
    "                n_epoch=epoch, earlystop_patience=10, device=device, gpus=['cuda:0', 'cuda:1'], model_path=save_dir)\n",
    "            mtl_trainer.fit(train_dataloader, val_dataloader)\n",
    "            auc = mtl_trainer.evaluate(mtl_trainer.model, test_dataloader)\n",
    "            print(f'lr: {learning_rate}, bs: {batch_size}, wd: {weight_decay}')\n",
    "            print(f'test auc: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d30878-1c95-4eef-90ea-4a5f720a5e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_name, epoch, learning_rate, batch_size, weight_decay, device, save_dir, seed):\n",
    "    torch.manual_seed(seed)\n",
    "    if model_name == \"SharedBottom\":\n",
    "        features, x_train, y_train, x_val, y_val, x_test, y_test = get_ali_ccp_data_dict(model_name)\n",
    "        task_types = [\"classification\", \"classification\"]\n",
    "        model = SharedBottom(features, task_types, bottom_params={\"dims\": [117]}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}])\n",
    "    elif model_name == \"ESMM\":\n",
    "        user_features, item_features, x_train, y_train, x_val, y_val, x_test, y_test = get_ali_ccp_data_dict(model_name)\n",
    "        task_types = [\"classification\", \"classification\", \"classification\"]  #cvr,ctr,ctcvr\n",
    "        model = ESMM(user_features, item_features, cvr_params={\"dims\": [16, 8]}, ctr_params={\"dims\": [16, 8]})\n",
    "    elif model_name == \"MMOE\":\n",
    "        features, x_train, y_train, x_val, y_val, x_test, y_test = get_ali_ccp_data_dict(model_name)\n",
    "        task_types = [\"classification\", \"classification\"]\n",
    "        model = MMOE(features, task_types, 8, expert_params={\"dims\": [16]}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}])\n",
    "    elif model_name == \"PLE\":\n",
    "        features, x_train, y_train, x_val, y_val, x_test, y_test = get_ali_ccp_data_dict(model_name)\n",
    "        task_types = [\"classification\", \"classification\"]\n",
    "        model = PLE(features, task_types, n_level=1, n_expert_specific=2, n_expert_shared=1, expert_params={\"dims\": [16]}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}])\n",
    "    elif model_name == \"AITM\":\n",
    "        task_types = [\"classification\", \"classification\"]\n",
    "        features, x_train, y_train, x_val, y_val, x_test, y_test = get_ali_ccp_data_dict(model_name)\n",
    "        model = AITM(features, 2, bottom_params={\"dims\": [32, 16]}, tower_params_list=[{\"dims\": [8]}, {\"dims\": [8]}])\n",
    "\n",
    "    dg = DataGenerator(x_train, y_train)\n",
    "    train_dataloader, val_dataloader, test_dataloader = dg.generate_dataloader(x_val=x_val, y_val=y_val, x_test=x_test, y_test=y_test, batch_size=batch_size)\n",
    "\n",
    "    #adaptive weight loss:\n",
    "    #mtl_trainer = MTLTrainer(model, task_types=task_types, optimizer_params={\"lr\": learning_rate, \"weight_decay\": weight_decay}, adaptive_params={\"method\": \"uwl\"}, n_epoch=epoch, earlystop_patience=10, device=device, model_path=save_dir)\n",
    "\n",
    "    mtl_trainer = MTLTrainer(model, task_types=task_types, optimizer_params={\"lr\": learning_rate, \"weight_decay\": weight_decay}, n_epoch=epoch, earlystop_patience=30, device=device, model_path=save_dir)\n",
    "    mtl_trainer.fit(train_dataloader, val_dataloader)\n",
    "    auc = mtl_trainer.evaluate(mtl_trainer.model, test_dataloader)\n",
    "    print(f'test auc: {auc}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_name', default='SharedBottom')\n",
    "    parser.add_argument('--epoch', type=int, default=1)\n",
    "    parser.add_argument('--learning_rate', type=float, default=1e-3)\n",
    "    parser.add_argument('--batch_size', type=int, default=1024)\n",
    "    parser.add_argument('--weight_decay', type=float, default=1e-4)\n",
    "    parser.add_argument('--device', default='cpu')  #cuda:0\n",
    "    parser.add_argument('--save_dir', default='./')\n",
    "    parser.add_argument('--seed', type=int, default=2022)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(args.model_name, args.epoch, args.learning_rate, args.batch_size, args.weight_decay, args.device, args.save_dir, args.seed)\n",
    "\"\"\"\n",
    "python run_ali_ccp_multi_task.py --model_name SharedBottom\n",
    "python run_ali_ccp_multi_task.py --model_name ESMM\n",
    "python run_ali_ccp_multi_task.py --model_name MMOE\n",
    "python run_ali_ccp_multi_task.py --model_name PLE\n",
    "python run_ali_ccp_multi_task.py --model_name AITM\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4565e70a-3d55-4c1b-a433-9a9cbcd8baad",
   "metadata": {},
   "source": [
    "### 3、carts数据集生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129bdf1-c434-4c7c-bd33-92250f5a501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_origin['carts'] = 0\n",
    "df_val['carts'] = 0\n",
    "df_test['carts'] = 0\n",
    "\n",
    "df_train_origin['index'] = df_train_origin.index\n",
    "df_val['index'] = df_val.index\n",
    "df_test['index'] = df_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a89608e-a7da-4b04-9822-dd4c2bf92207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "model, data_loader = mtl_trainer.model, val_dataloader\n",
    "\n",
    "model.eval()\n",
    "predicts = list()\n",
    "indexies = list()\n",
    "with torch.no_grad():\n",
    "    tk0 = tqdm.tqdm(data_loader, desc=\"predict\", smoothing=0, mininterval=1.0)\n",
    "    for i, (x_dict, ys) in enumerate(tk0):\n",
    "        x_dict = {k: v.to(mtl_trainer.device) for k, v in x_dict.items()}\n",
    "        y_preds = model(x_dict)\n",
    "        predicts.extend(y_preds.tolist())\n",
    "        indexies.extend(x_dict['index'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab8bf4-5ef2-49fc-9054-e584386b1996",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_pred = pd.DataFrame(predicts, columns=['p_purchase','p_click'])\n",
    "print(1)\n",
    "df_val_index = pd.DataFrame(indexies, columns=['index'])\n",
    "print(2)\n",
    "df_val_ipred = pd.concat([df_val_index, df_val_pred], axis=1)\n",
    "print(3)\n",
    "df_val_ipred.sort_values('index', inplace=True)\n",
    "df_val_ipred.reset_index(drop=True, inplace=True)\n",
    "print(4)\n",
    "df_val_end = pd.concat([df_val_ipred, df_val], axis=1)\n",
    "df_val_end.drop(columns=['index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bdae1-97a6-4a4c-8683-944615406ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_val_end.loc[:,'p_purchase'].quantile(q=0.05)\n",
    "threshold = df_val_end[(df_val_end['click']==1) & (df_val_end['purchase']==0)]['p_purchase'].quantile(q=0.928) # 13/14=0.928, click,carts,purchase 1,0,0:1,1,0:1,1,1 => 167:13:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8be53-d223-4717-a7dd-37f8920a30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_end['carts']=0\n",
    "df_val_end.loc[df_val_end['p_purchase']>=threshold, 'carts']=1\n",
    "# df_val_end.loc[df_val_end['p_click']>=0.19431710243225098,'carts']=1\n",
    "df_val_end.loc[df_val_end['purchase']==1,'carts']=1\n",
    "df_val_end.loc[df_val_end['click']==0,'carts']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7aa54d-a057-4657-8191-824832d3d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_end.loc[:,['click','carts','purchase']].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f44260d-0aad-4f10-b49b-5d78a31b34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_end.to_csv('ali_ccp_val_with_carts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71557708-2b77-4e90-828c-d79c8a1f3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
